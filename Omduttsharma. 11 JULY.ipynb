{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc4e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543eb17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Missing values in each column:\n",
      " Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "Data preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "file_path =(r\"C:\\Users\\Student\\Downloads\\creditcard(1) (1).xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X = df.drop(columns=['Class'])  \n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c07784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic Regression': {'Accuracy': 0.9991222218320986, 'Precision': 0.8636363636363636, 'Recall': 0.5816326530612245, 'F1 Score': 0.6951219512195121}, 'Random Forest': {'Accuracy': 0.9995786664794073, 'Precision': 0.9743589743589743, 'Recall': 0.7755102040816326, 'F1 Score': 0.8636363636363635}, 'Decision Tree': {'Accuracy': 0.9990519995786665, 'Precision': 0.7, 'Recall': 0.7857142857142857, 'F1 Score': 0.7403846153846153}, 'SVM': {'Accuracy': 0.9993153330290369, 'Precision': 0.9682539682539683, 'Recall': 0.6224489795918368, 'F1 Score': 0.7577639751552796}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "model_performance = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    model_performance[model_name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "print(model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d542157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[56855     9]\n",
      " [   41    57]]\n",
      "Precision: 0.8636363636363636\n",
      "Recall: 0.5816326530612245\n",
      "F1 Score: 0.6951219512195121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "lr_model = models['Logistic Regression']\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr)\n",
    "recall = recall_score(y_test, y_pred_lr)\n",
    "f1 = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b206f0f8",
   "metadata": {},
   "source": [
    "# QUES 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6316bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#To ensure a machine learning model for credit card fraud detection remains effective over time, use the following strategies:\n",
    "\n",
    "### Technical Strategies\n",
    "\n",
    "1. Regular Model Retraining: Update the model with new data periodically.\n",
    "2. Adaptive Algorithms: Use algorithms that adapt to changes in data distribution.\n",
    "3. Model Monitoring: Track performance metrics and set up alerts for significant drops.\n",
    "4. Data Pipeline Management: Maintain a robust data pipeline with quality checks.\n",
    "5. Ensemble Methods: Combine predictions from multiple models.\n",
    "6. Feature Engineering: Update features to capture emerging fraud patterns.\n",
    "\n",
    "\n",
    "    Operational Strategies\n",
    "\n",
    "1. Human-in-the-Loop: Use feedback from fraud analysts to refine the model.\n",
    "2. Continuous Evaluation: Regularly test the model on validation sets or with A/B testing.\n",
    "3. Collaboration with Fraud Analysts: Work closely with fraud detection teams.\n",
    "4. Model Governance: Document and manage changes to the model.\n",
    "5. Scalability and Performance: Ensure the infrastructure can handle increasing data volumes.\n",
    "6. Stakeholder Communication: Keep stakeholders informed about the modelâ€™s performance and updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70cb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce776d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
